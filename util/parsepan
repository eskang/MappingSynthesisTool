#!/usr/bin/python
#
# parsepan - parse pan verification reports
#
# Copyright (c) 2014 - Theo C. Ruys.
#
# This script is written as a support tool for the SPIN verifier.
# All Rights Reserved. This software is for educational purposes only.
# No guarantee whatsoever is expressed or implied by the distribution of 
# this code. Permission is given to distribute this code provided that
# this introductory message is not removed and no monies are exchanged.
#
# SPIN is developed by Gerard J. Holzmann (http://spinroot.com/).
# This script is written by Theo C. Ruys (theo dot ruys at gmail dot com).
#
# DESCRIPTION
#   Python script to get information out of verification reports
#   as generated by SPIN's pan verifier. parsepan also recognizes
#   information added by the runspin script.
#
#   This script is (very) loosely based on the perl script ppr
#   originally described in [Ruys - PhD Thesis 2001].
#
# AUTHOR
#   Theo C. Ruys
#
# DOCUMENTATION
#   See parespan.1, parsepan.html or parsepan.pdf.
#
# VERSION
#   0.9     2014.04.19  First public version.
#
# USAGE
#   execute "parsepan -h" to get the list of known options

import sys
import re
import os
import argparse
import traceback

# -- line patterns --------------------------------------------------------

pan_lines = [
# information added by runspin
(r'> this report\s*:\s*(.*)',
    ['rs_report_file']),
(r'> promela file\s*:\s*(.*)',
    ['rs_promela_file']),
(r'> date\s*:\s*(.*)',
    ['rs_verification_date']),
(r'> spin version\s*:\s*(.*)',
    ['rs_spin_version']),
(r'> gcc version\s*:\s*(.*)',
    ['rs_gcc_version']),
(r'> config source\s*:\s*(.*)',
    ['rs_config_source']),
(r'> config file\s*:\s*(.*)\s*\(option -f\)',
    ['rs_config_file']),
(r'> config name\s*:\s*(.*)',
    ['rs_config_name']),
(r'> runspin command\s*:\s*(.*)',
    ['rs_runspin_command']),
(r'> spin command\s*:\s*(.*)',
    ['rs_spin_command']),
(r'> gcc command\s*:\s*(.*)',
    ['rs_gcc_command']),
(r'> pan command\s*:\s*(.*)',
    ['rs_pan_command']),

# regular SPIN output: based on wrapup() from pan.c (SPIN 6.2.7)
# omitted: output from -DDEBUG -DTRIX -DPEG -DVAR_RANGES, and unreached states
(r'\(Spin Version ([0-9\.]+) -- (.*)\)', 
    ['spin_version', 'spin_version_date']),
(r'Warning:\s*(.*)', 
    ['warning']),
(r'(\+) Multi-Core \(using (.*) cores\)', 
    ['opt_multi_core', 'multi_cores']),
(r'(\+) Multi-Core \(NCORE=([0-9]+)\)', 
    ['opt_multi_core', 'multi_core_ncore']),
(r'(\+) Multi-Core \(NCORE=([0-9]+)\s*-z(.*)\)', 
    ['opt_multi_core', 'multi_core_ncore', 'multi_core_z_handoff']),
(r'(\+) Seperate Hash Tables', 
    ['opt_seperate_hash_tables']),
(r'(\+) Disk storage', 
    ['opt_disk_storage']),
(r'(\+) Breadth-First Search', 
    ['opt_bfs']),
(r'(\+) Partial Order Reduction', 
    ['opt_po_reduction']),
(r'(\+) Reverse Depth-First Search Order', 
    ['opt_reverse_dfs']),
(r'(\+) Reverse Transition Ordering', 
    ['opt_reverse_transition_ordering']),
(r'(\+) Randomized Transition Ordering', 
    ['opt_random_transition_ordering']),
(r'(\+) Randomized Process Ordering', 
    ['opt_random_process_ordering']),
(r'(\+) Scheduling Restriction \(-L([0-9]+)\)', 
    ['opt_scheduling_restriction', 'scheduling_max']),
(r'(\+) Tree Index Compression', 
    ['opt_tree_index_compression']),
(r'(\+) Compression', 
    ['opt_compression']),
(r'(\+) Graph Encoding \(-DMA=([0-9]+)\)', 
    ['opt_graph_encoding', 'graph_encoding_ma']),
(r'Restarted from checkpoint\s+(.*)', 
    ['graph_encoding_restarted_from_checkpoint']),
(r'(\+) FullStack Matching', 
    ['opt_fullstack_matching']),
(r'(Bit) statespace search for:', 
    ['opt_bit_statespace_search']),
(r'(Hash-Compact)\s+([0-9]+)\s+search for:', 
    ['opt_hash_compact_search', 'hash_compact_hc']),
(r'(Full) statespace search for:', 
    ['opt_full_statespace_search']),
(r'notrace assertion\s*(\+)', 
    ['opt_notrace_assertion']),
(r'trace assertion\s*(\+)', 
    ['opt_trace_assertion']),
(r'never claim\s*(\+)\s*\((.*)\)', 
    ['opt_never_claim', 'never_claim_note']),
(r'never claim\s*(\-)\s*\((.*)\)', 
    ['opt_never_claim', 'never_claim_note']),
(r'assertion violations\s*(\+|\-)\s*\((.*)\)', 
    ['opt_assertion_violations', 'assertion_note']),
(r'assertion violations\s*(\+)', 
    ['opt_assertion_violations']),
(r'non-progress cycles\s*(\+)\s*\(fairness (.*)\)', 
    ['opt_non_progress_cycles', 'fairness']),
(r'non-progress cycles\s*(\-)\s*\(not selected\)', 
    ['opt_non_progress_cycles']),
(r'acceptance\s+cycles\s*(\+)\s*\(fairness (.*)\)', 
    ['opt_acceptance_cycles', 'fairness']),
(r'acceptance\s+cycles\s*(\-)\s*\(not selected\)', 
    ['opt_acceptance_cycles']),
(r'cycle checks\s*(\+|\-)\s*\((.*)\)', 
    ['opt_cycle_checks', 'cycle_checks_note']),
(r'invalid end states\s*(\-)\s*\((.*)\)', 
    ['opt_invalid_end_states', 'invalid_end_states_note']),
(r'invalid end states\s*(\+)\s*', 
    ['opt_invalid_end_states']),
(r'State-vector ([0-9]+) byte, depth reached ([0-9]+), errors: ([0-9]+)', 
    ['state_vector', 'depth', 'errors']),
# from wrap_stats():
(r'(.*)\s+states, stored \((.*) visited\)', 
    ['states_stored', 'states_visited']),
(r'(.*)\s+states, stored', 
    ['states_stored']),
(r'(.*)\s+states lost \(lack of queue memory\)', 
    ['bfs_par_states_lost']),
(r'(.*)\s+nominal states \(.*\)', 
    ['bfs_nominal_states']),
(r'(.*)\s+rvs succeeded', 
    ['bfs_rvs_succeeded']),
(r'(.*)\s+states, matched', 
    ['states_matched']),
(r'(.*)\s+matches within stack', 
    ['check_matches_within_stack']),
(r'(.*)\s+transitions \(.*\)', 
    ['transitions']),
(r'(.*)\s+atomic steps', 
    ['atomic_steps']),
(r'(.*)\s+lost messages', 
    ['lost_messages']),
(r'hash conflicts:\s+(.*)\s+\(resolved\)', 
    ['hash_conflicts']),
(r'the hash table is (.*) filled.*', 
    ['hash_table_filling_percentage']),
(r'(.*)\s+states allocated for dfs stack', 
    ['check_states_allocated_dfs_stack']),
(r'hash factor: (.*) \(best if > 100.\)', 
    ['hash_factor']),
(r'bits set per state: (.*) \((.*)\)', 
    ['hash_bits_set_per_state', 'hash_bits_per_state_option']),
(r'bfs disk reads: (.*) writes (.*) -- diff (.*)', 
    ['bfs_disk_reads', 'bfs_disk_reads', 'bfs_disk_diff']),
# back to wrapup():
(r'MA stats: -DMA=\s*([0-9]+)\s*is sufficient', 
    ['ma_sufficient']),
(r'Minimized Automaton:\s*([0-9]+)\s*nodes and\s*([0-9]+)\s*edges', 
    ['ma_nodes', 'ma_edges']),
(r'stackframes:\s*([0-9]+)/([0-9]+)',
    ['check_stackframes_smax', 'check_stackframes_svmax']),
(r'stats: fa ([0-9]+), fh ([0-9]+), zh ([0-9]+), zn ([0-9]+) - check ([0-9]+) holds ([0-9]+)',
    ['check_stats_fa', 'check_stats_fh', 'check_stats_zh', 'check_stats_zn', 'check_stats_check', 'check_stats_holds']),
(r'stack stats: puts ([0-9]+), probes ([0-9]+), zaps ([0-9]+)',
    ['check_stack_puts', 'check_stack_probes', 'check_stack_zaps']),
(r'Stats on (memory usage) \(in Megabytes\):', 
    ['opt_mem_stats_memory_usage']),
(r'(.*)\s+equivalent memory usage for states', 
    ['mem_stats_equivalent_memory_states']),
(r'\(stored\*\(State\-vector \+ overhead\)\)', 
    ['opt_mem_stats_formula']),
(r'(.*)\s+shared memory reserved for state storage', 
    ['mem_stats_shared_memory']),
(r'in\s+([0-9]+)\s+local heaps of\s+(.*)\s+MB each', 
    ['mem_stats_local_heaps_number', 'mem_stats_local_heaps_size']),
(r'(.*)\s+memory used for hash array\s+\((.*)\)', 
    ['mem_stats_bit_hash_array', 'mem_stats_bit_hash_array_option']),
(r'(.*)\s+memory used for bit stack', 
    ['mem_stats_bit_stack']),
(r'(.*)\s+actual memory usage for states', 
    ['mem_stats_actual_memory_states']),
(r'(.*)\s+actual memory usage for states\s+\(compression:\s+(.*)\)', 
    ['mem_stats_actual_memory_states', 'mem_stats_actual_memory_compression']),
(r'(.*)\s+actual memory usage for states\s+\((less than 1k)\)', 
    ['mem_stats_actual_memory_states', 'mem_stats_actual_memory_compression']),
(r'state-vector as stored =\s+([0-9]+)\s+byte\s+\+\s+([0-9]+)\s+byte overhead', 
    ['mem_stats_state_vector', 'mem_stats_state_vector_overhead']),
(r'(.*)\s+shared memory used for hash table\s+\((.*)\)', 
    ['mem_stats_hash_table_shared_memory', 'mem_stats_hash_table_option']),
(r'(.*)\s+memory used for hash table\s+\((.*)\)', 
    ['mem_stats_hash_table_memory', 'mem_stats_hash_table_option']),
(r'(.*)\s+memory used for DFS stack\s+\((.*)\)', 
    ['mem_stats_dfs_stack_memory', 'mem_stats_dfs_stack_option']),
(r'(.*)\s+shared memory used for work-queues', 
    ['mem_stats_work_queues_shared_memory']),
(r'in ([0-9]+) queues of (.*) MB each \+ a global q of (.*) MB',
    ['mem_stats_work_queues_number', 'mem_stats_work_queues_size', 'mem_stats_work_queues_global']),
(r'(.*)\s+other \(proc and chan stacks\)', 
    ['mem_stats_memory_other']),
(r'(.*)\s+memory lost to fragmentation', 
    ['mem_stats_memory_fragmentation']),
(r'(.*)\s+total non-shared memory usage', 
    ['mem_stats_memory_total']),
(r'(.*)\s+total actual memory usage', 
    ['mem_stats_memory_total']),
(r'(.*)\s+memory usage \(Mbyte\)', 
    ['mem_stats_memory_usage']),
(r'nr of templates: (\[ 0:globals 1:chans 2:procs \])', 
    ['mem_stat_collapse_template']),
(r'collapse counts: (\[.*\])', 
    ['mem_stat_collapse_counts']),
(r'(.*)\s+loopstates hit', 
    ['loopstates']),
# from report_time():
(r'pan: elapsed time (.*) seconds', 
    ['elapsed_time']),
(r'pan: rate (.*) states\/second', 
    ['rate_states_per_second']),
(r'pan: avg transition delay (.*) usec', 
    ['avg_transition_delay']),

# extra information, e.g. UNIX' time (differs for OS, shell, etc.)
(r'real\s+(.*)', 
    ['xtra_real_time']),
(r'user\s+(.*)', 
    ['xtra_user_time']),
(r'sys\s+(.*)', 
    ['xtra_sys_time']),

]

# compile regex patterns
line_patterns=[]
for (regex,groups) in pan_lines:
    line_patterns.append((re.compile(regex),groups))

# -- functions ------------------------------------------------------------

def print_items(items_found, keys2report, args):
    delim = delimiters[args.delimiter]

    if not hasattr(print_items, "printed_header"):
         print_items.printed_header = False 

    if args.lines:
        # each (k,v) pair on a separate line
        for k in keys2report:
            v = items_found[k] if k in items_found else '-'
            if args.quotes:
                print '"%s"%s"%s"' % (k,delim,v)
            else:
                print '%s%s%s' % (k,delim,v)
    else:
        # normal: all items on a single line
        if (args.header and not print_items.printed_header):
            if args.quotes:
                print delim.join('"{0}"'.format(w) for w in keys2report)
            else:
                print delim.join(keys2report)
            print_items.printed_header = True

        selected_items = []
        for k in keys2report:
            v = items_found[k] if k in items_found else '-'
            selected_items.append(v)
        if args.quotes:
            print delim.join('"{0}"'.format(w) for w in selected_items)
        else:
            print delim.join(selected_items)

def parse_pan_results(f, args):
    global keys2report
    # If keys2report is not yet set, we should build it to ensure that 
    # the order of the items is the same for all verification reports.
    build_keys2report = (len(keys2report) == 0)

    items_found=dict()
    for line in f:
        l = line.strip()
        ismatched = False
        for (line_pattern,groups) in line_patterns:
            mtch=line_pattern.match(l)
            if (mtch):
                ismatched = True
                for (name,i) in zip(groups, range(1, len(groups)+1)):
                    val = mtch.group(i)
                    if build_keys2report:
                        keys2report.append(name)

                    if name in items_found.keys():
                        # apparently a new file with verification results
                        print_items(items_found, keys2report, args)
                        items_found=dict()

                    items_found[name] = val
                break # only one line pattern can be matched

        if not ismatched and len(l)>0 and args.debug:
            sys.stderr.write("# %s\n" % l)

    # print items from last report file
    print_items(items_found, keys2report, args)


# -- globals --------------------------------------------------------------

version = "0.9 -- 19 Apr 2014"
progname = "parsepan"

keys2report=[]
delimiters={'c': ',', 't': '\t', '=': '='}

# -- main -----------------------------------------------------------------

scriptdescr = "%s %s - parse pan verification reports" % (progname, version)

import argparse
parser = argparse.ArgumentParser(description=scriptdescr)
parser.add_argument('-a', '--allnames', help='print all recognized attribute names', action='store_true')
parser.add_argument('-d', '--delimiter', help='delimiter between items', type=str, choices=['c','t','='], default='t')
parser.add_argument('-k', '--keyfile', help='only report on the items from the specified file', type=str)
parser.add_argument('-l', '--lines', help='print each (k,v) item on a separate line', action='store_true')
parser.add_argument('-q', '--quotes', help='wrap all values into double quotes', action='store_true')
parser.add_argument('-s', '--summary', help='very concise summary of verification reports', action='store_true')
parser.add_argument('-t', '--header', help='print header row in horizontaal view', action='store_true')
parser.add_argument('-v', '--version', help='print version number and exit', action='store_true')
parser.add_argument('-x', '--debug', help='write lines not recognized by script (prefixed by #)', action='store_true')
parser.add_argument("inputfiles", help="input files with pan verification reports", nargs='*')
args = parser.parse_args()

if args.version:
    print "%s %s\n" % (name, version)
    exit(0)

if args.allnames:
    # print all known keys of items
    keys=[]
    for (line_pattern, groups) in line_patterns:
        keys.extend(groups)
    print '\n'.join(sorted(set(keys)))
    exit(0)

if args.summary:
    keys2report = ['rs_promela_file', 'rs_config_name', 'errors', 'states_stored', 'state_vector']

if args.keyfile is not None:
    try:
        f_keys = open(args.keyfile, 'r')
        keys2report = f_keys.read().splitlines()
        # remove commented items which start with '#'
        keys2report = [s for s in keys2report if not s.startswith('#') ]

    except IOError as e:
        sys.stderrr.write("error: I/O error({0}): {1}\n".format(e.errno, e.strerror))
    finally:
        f_keys.close()

    if len(keys2report) == 0:
        sys.stderr.write("%s: error - no keys found in %s\n" % (progname, args.keyfile))
        exit(1)

if len(args.inputfiles) > 0:
    for fname in args.inputfiles:
        try:
            f = open(fname, 'r')
            parse_pan_results(f, args)
        except IOError as e:
            sys.stderrr.write("error: I/O error({0}): {1}\n".format(e.errno, e.strerror))
        finally:
            f.close()
else:
    # get input from standard input
    parse_pan_results(sys.stdin, args)